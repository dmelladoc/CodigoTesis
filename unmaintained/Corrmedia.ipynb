{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui veremos que pasa si calculamos la correlación por batches. cuanto cambia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.stats import pearsonr\n",
    "from ast import literal_eval\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pydicom as dcm\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import interpolate\n",
    "from torchvision.transforms import v2 as transforms\n",
    "\n",
    "from FindClf import ImageIO\n",
    "from FindClf.Models import create_efficientNetV2\n",
    "from FindClf.DetectorOps import Detector\n",
    "from CorrRELAX.Transforms import get_transforms\n",
    "from CorrRELAX.WindowOps import get_windows\n",
    "from CorrRELAX.Algorithm import CorrRelax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PARAMETROS\n",
    "LABEL_NAMES = [\n",
    "    \"No Finding\",\n",
    "    \"Mass\",\n",
    "    \"Suspicious Calcification\",\n",
    "    \"Asymmetries\",\n",
    "    \"Architectural Distortion\",\n",
    "    \"Suspicious Lymph Node\",\n",
    "    \"Skin Thickening\",\n",
    "    \"Retractions\",\n",
    "]\n",
    "\n",
    "batch_size = 32\n",
    "window_size = 256\n",
    "window_shape = (window_size, window_size)\n",
    "stride = 32\n",
    "mask_size = 8\n",
    "mask_shape = (mask_size, mask_size)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrir la imagen de evaluación, buscando sus datos dentro de la tabla de anotaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"finding_annotations_V2.csv\")\n",
    "image_id = \"531bba59b58ee255662e46898934195e\"\n",
    "sample = df.groupby(\"image_id\").get_group(image_id)\n",
    "study_id = sample[\"study_id\"].values[0]\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impath = os.path.join(\"path/to/dataset\", study_id, image_id + \".dicom\")\n",
    "if not os.path.exists(impath):\n",
    "    raise FileNotFoundError(f\"Imagen {impath} no encontrada\")\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "\n",
    "image = ImageIO.load_dicom(impath)\n",
    "ax[0].imshow(image, cmap=\"gray\")\n",
    "ax[0].set_title(f\"Original ({image.dtype})\")\n",
    "image = ImageIO.clahefusion((image * 255).astype(np.uint8), thresholds=[1.0, 2.0])\n",
    "ax[1].imshow(image)\n",
    "ax[1].set_title(f\"CLAHE ({image.dtype})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aplicamos el detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = detector = Detector(\"ROIdetector/roidet_mammo.pth\", device=device)\n",
    "xmin, ymin, xmax, ymax = detector.get_roi(image)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image, cmap=\"gray\")\n",
    "rect = Rectangle(\n",
    "    (xmin, ymin), xmax - xmin, ymax - ymin, linewidth=1, edgecolor=\"r\", facecolor=\"none\"\n",
    ")\n",
    "ax.add_patch(rect)\n",
    "ax.set_title(\"ROI Detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped = image[ymin:ymax, xmin:xmax]\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(cropped, cmap=\"gray\")\n",
    "ax.set_title(\"Cropped Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelpath = 'models/findclfV4.1_EfficientNetV2.pth'\n",
    "modelpath = \"checkpoints/20241106_214840/EfficientNetV2_final.pth\"\n",
    "model = create_efficientNetV2(len(LABEL_NAMES))\n",
    "state_dict = torch.load(modelpath, weights_only=True, map_location=device)\n",
    "model.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Modelo cargado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = get_transforms(window_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos la imagen en ventanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows, (dx, dy) = get_windows(cropped, window_size, stride)\n",
    "ndx, ndy = len(dx), len(dy)\n",
    "print(f\"Tenemos en total {len(windows)} ventanas ({ndx}x{ndy})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleccionamos una ventana aleatoria\n",
    "n = 2550  # np.random.randint(len(windows))\n",
    "window = windows[n]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a construir CorRELAX desde cero, porque vamos a tener que obtener todas las distancias y ver cuanto cambia si tomamos promedios de submuestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necesitamos nuestro generador de mascaras\n",
    "def make_masks(n_iters, mask_shape, p=0.5):\n",
    "    for _ in range(n_iters):\n",
    "        masks = (torch.rand(batch_size, 1, *mask_shape, device=device) > p).float()\n",
    "        interp = interpolate(\n",
    "            masks, size=window_shape, mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        yield interp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_masks = 2560\n",
    "n_iters = n_masks // batch_size\n",
    "print(f\"Generando {n_masks} mascaras de {mask_shape} en {n_iters} iteraciones\")\n",
    "\n",
    "# almacenamos los resultados de las distancias\n",
    "full_results = {name: [] for name in [\"distVect\", \"predVect\", \"prediction\"]}\n",
    "batch_results = {name: [] for name in [\"corrDist\", \"corrPred\"]}\n",
    "distance_fn = torch.nn.CosineSimilarity(dim=1)  # Distancia Coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  # Vamos a evaluar a diferentes batches y vamos a registrarlos\n",
    "with torch.no_grad():\n",
    "    # Preprocesamos la ventana\n",
    "    window_tensor = torch.from_numpy(window).to(device)\n",
    "    window_tensor = transforms(window_tensor)\n",
    "\n",
    "    ## CorRELAX\n",
    "    # debemos evaluar la imagen con el modelo\n",
    "    model_output = model(window_tensor)\n",
    "    image_pred = torch.sigmoid(model_output[\"Classifier\"])  # predicción\n",
    "    image_vect = model_output[\"Features\"]  # obtenemos las features internas\n",
    "\n",
    "    # Ahora, debemos evaluar las versiones enmascaradas de la imagen\n",
    "    for masks in tqdm(make_masks(n_iters, mask_shape), total=n_iters):\n",
    "        # aplicamos la mascara\n",
    "        masked_window = window_tensor * masks\n",
    "        masked_output = model(masked_window)\n",
    "        # Obtenemos la predicción y las features internas para cada subset de mascaras\n",
    "        masked_pred = torch.sigmoid(masked_output[\"Classifier\"])\n",
    "        masked_vect = masked_output[\"Features\"]\n",
    "\n",
    "        # Calculamos la distancia entre los features originales y enmascarados\n",
    "        dist_vectors = distance_fn(image_vect, masked_vect).squeeze()\n",
    "        full_results[\"distVect\"].append(dist_vectors)\n",
    "\n",
    "        # Distancia entre predicciones originales y enmascaradas\n",
    "        pred_vectors = distance_fn(image_pred, masked_pred).squeeze()\n",
    "        full_results[\"predVect\"].append(pred_vectors)\n",
    "\n",
    "        # y Acumulamos las predicciones de las mascaras\n",
    "        full_results[\"prediction\"].append(masked_pred)\n",
    "\n",
    "        # -- Calcularemos la correlación en cada batch\n",
    "        corr_dist = torch.corrcoef(torch.stack([dist_vectors, pred_vectors], dim=0))[\n",
    "            0, 1\n",
    "        ]\n",
    "        corr_pred = torch.corrcoef(\n",
    "            torch.cat([dist_vectors.unsqueeze(1), masked_pred], dim=1).T\n",
    "        )[0, 1:]\n",
    "\n",
    "        batch_results[\"corrDist\"].append(corr_dist.detach().item())\n",
    "        batch_results[\"corrPred\"].append(corr_pred.detach().tolist())\n",
    "\n",
    "    # Concatenamos los resultados\n",
    "    full_results[\"distVect\"] = (\n",
    "        torch.cat(full_results[\"distVect\"], dim=0).detach().cpu().numpy()\n",
    "    )\n",
    "    full_results[\"predVect\"] = (\n",
    "        torch.cat(full_results[\"predVect\"], dim=0).detach().cpu().numpy()\n",
    "    )\n",
    "    full_results[\"prediction\"] = (\n",
    "        torch.cat(full_results[\"prediction\"], dim=0).detach().cpu().numpy()\n",
    "    )\n",
    "\n",
    "    batch_results[\"corrDist\"] = np.nan_to_num(np.array(batch_results[\"corrDist\"]))\n",
    "    batch_results[\"corrPred\"] = np.nan_to_num(np.array(batch_results[\"corrPred\"]))\n",
    "\n",
    "    # Queda pendiente la correlación de las distancias y las predicciones para evaluar importancia de las features.\n",
    "\n",
    "# print(results['distVect'].shape, results['predVect'].shape, results['prediction'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_results[\"corrDist\"].shape, batch_results[\"corrPred\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = int(1 + np.log2(len(batch_results[\"corrDist\"])))\n",
    "\n",
    "fig, ax = plt.subplot_mosaic([[\"meandist\", \"meanpred\"]])\n",
    "ax[\"meandist\"].hist(batch_results[\"corrDist\"], bins=3 * k, range=(0, 1))\n",
    "ax[\"meanpred\"].matshow(batch_results[\"corrPred\"], cmap=\"seismic\", vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Media = {batch_results['corrDist'].mean():.4f} ± {batch_results['corrDist'].std():.4f}\"\n",
    ")\n",
    "for i, name in enumerate(LABEL_NAMES):\n",
    "    print(\n",
    "        f\"CorrPred({name:^24}) = {batch_results['corrPred'].mean(axis=0)[i]:.4f} ± {batch_results['corrPred'].std(axis=0)[i]:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlación de toda la población"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlaciones\n",
    "\n",
    "# Correlación entre distancia de features y distancia de predicciones\n",
    "full_corr_dist = pearsonr(full_results[\"distVect\"], full_results[\"predVect\"]).statistic\n",
    "\n",
    "# Correlación entre distancia de features y predicciones de mascaras\n",
    "full_corr_pred = pearsonr(\n",
    "    full_results[\"distVect\"][..., np.newaxis], full_results[\"prediction\"]\n",
    ").statistic\n",
    "\n",
    "print(f\"2560 mascaras\\nCorrDist = {full_corr_dist:.4f}\")\n",
    "for i, name in enumerate(LABEL_NAMES):\n",
    "    print(f\"CorrPred [{name:^24}] = {full_corr_pred[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, que pasa si procesamos con mas o menos batches, cuanto cambia el resultado...\n",
    "\n",
    "\n",
    "\n",
    "| Batches  | CorDist         | CorrPred NFind  | CorrPred Asymm  | Tiempo (it/s) | %datos/s |\n",
    "|---------:|:---------------:|:---------------:|:---------------:|:-------------:|:-------:|\n",
    "| Full     | 0.7725          | 0.9224          | 0.0539          | -             | -       |\n",
    "| 96       | 0.7867 ± 0.0302 | 0.9238 ± 0.0130 | 0.0854 ± 0.0752 |  6.14         | 23.025  |\n",
    "| 64       | 0.7879 ± 0.0412 | 0.9255 ± 0.0184 | 0.0638 ± 0.1327 |  8.64         | 21.600  |\n",
    "| 48       | 0.7922 ± 0.0410 | 0.9281 ± 0.0152 | 0.0957 ± 0.1166 | 11.25         | 21.093  |\n",
    "| 36       | 0.8026 ± 0.0483 | 0.9237 ± 0.0203 | 0.0676 ± 0.1433 | 15.48         | 21.768  |\n",
    "| 32       | 0.7956 ± 0.0576 | 0.9267 ± 0.0225 | 0.0570 ± 0.1702 | 16.93         | 21.162  |\n",
    "| 24       | 0.8060 ± 0.0567 | 0.9292 ± 0.0227 | 0.0847 ± 0.1917 | 22.16         | 20.775  |\n",
    "| 16       | 0.8111 ± 0.0709 | 0.9272 ± 0.0343 | 0.0956 ± 0.2503 | 33.12         | 20.700  |\n",
    "| 12       | 0.8277 ± 0.0860 | 0.9284 ± 0.0378 | 0.1106 ± 0.2750 | 44.74         | 20.972  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 96  # Vamos a evaluar a diferentes batches y vamos a registrarlos\n",
    "n_iters = n_masks // batch_size\n",
    "print(f\"Generando {n_masks} mascaras de {mask_shape} en {n_iters} iteraciones\")\n",
    "batch_results = {name: [] for name in [\"corrDist\", \"corrPred\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Preprocesamos la ventana\n",
    "    window_tensor = torch.from_numpy(window).to(device)\n",
    "    window_tensor = transforms(window_tensor)\n",
    "    ## CorRELAX\n",
    "    # debemos evaluar la imagen con el modelo\n",
    "    model_output = model(window_tensor)\n",
    "    image_pred = torch.sigmoid(model_output[\"Classifier\"])  # predicción\n",
    "    image_vect = model_output[\"Features\"]  # obtenemos las features internas\n",
    "\n",
    "    # Ahora, debemos evaluar las versiones enmascaradas de la imagen\n",
    "    for masks in tqdm(make_masks(n_iters, mask_shape), total=n_iters):\n",
    "        # aplicamos la mascara\n",
    "        masked_window = window_tensor * masks\n",
    "        masked_output = model(masked_window)\n",
    "        # Obtenemos la predicción y las features internas para cada subset de mascaras\n",
    "        masked_pred = torch.sigmoid(masked_output[\"Classifier\"])\n",
    "        masked_vect = masked_output[\"Features\"]\n",
    "\n",
    "        # Calculamos la distancia entre los features originales y enmascarados\n",
    "        dist_vectors = distance_fn(image_vect, masked_vect).squeeze()\n",
    "        # full_results['distVect'].append(dist_vectors)\n",
    "\n",
    "        # Distancia entre predicciones originales y enmascaradas\n",
    "        pred_vectors = distance_fn(image_pred, masked_pred).squeeze()\n",
    "        # full_results['predVect'].append(pred_vectors)\n",
    "\n",
    "        # y Acumulamos las predicciones de las mascaras\n",
    "        # full_results['prediction'].append(masked_pred)\n",
    "\n",
    "        # -- Calcularemos la correlación en cada batch\n",
    "        corr_dist = torch.corrcoef(torch.stack([dist_vectors, pred_vectors], dim=0))[\n",
    "            0, 1\n",
    "        ]\n",
    "        corr_pred = torch.corrcoef(\n",
    "            torch.cat([dist_vectors.unsqueeze(1), masked_pred], dim=1).T\n",
    "        )[0, 1:]\n",
    "\n",
    "        batch_results[\"corrDist\"].append(corr_dist.detach().item())\n",
    "        batch_results[\"corrPred\"].append(corr_pred.detach().tolist())\n",
    "\n",
    "    batch_results[\"corrDist\"] = np.nan_to_num(np.array(batch_results[\"corrDist\"]))\n",
    "    batch_results[\"corrPred\"] = np.nan_to_num(np.array(batch_results[\"corrPred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Prueba Batch {batch_size}\")\n",
    "print(\n",
    "    f\"Media = {batch_results['corrDist'].mean():.4f} ± {batch_results['corrDist'].std():.4f}\"\n",
    ")\n",
    "for i, name in enumerate(LABEL_NAMES):\n",
    "    print(\n",
    "        f\"CorrPred({name:^24}) = {batch_results['corrPred'].mean(axis=0)[i]:.4f} ± {batch_results['corrPred'].std(axis=0)[i]:.4f}\"\n",
    "    )\n",
    "\n",
    "k = int(1 + np.log2(len(batch_results[\"corrDist\"])))\n",
    "\n",
    "fig, ax = plt.subplot_mosaic([[\"meandist\", \"meanpred\"]])\n",
    "ax[\"meandist\"].hist(batch_results[\"corrDist\"], bins=3 * k, range=(0, 1))\n",
    "ax[\"meanpred\"].matshow(batch_results[\"corrPred\"], cmap=\"seismic\", vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsamples = np.linspace(0, 2560, 21, dtype=int)\n",
    "all_corrdists, all_corrpreds = [], []\n",
    "\n",
    "for n_subsamples in subsamples[1:]:\n",
    "    # Tomamos un subconjunto de las distancias y predicciones\n",
    "    sub_distvect = results[\"distVect\"][:n_subsamples]\n",
    "    sub_predvect = results[\"predVect\"][:n_subsamples]\n",
    "    sub_prediction = results[\"prediction\"][:n_subsamples]\n",
    "\n",
    "    # Correlación entre distancia de features y distancia de predicciones\n",
    "    corr_dist = pearsonr(sub_distvect, sub_predvect).statistic\n",
    "    # Correlación entre distancia de features y predicciones de mascaras\n",
    "    corr_pred = pearsonr(sub_distvect[..., np.newaxis], sub_prediction).statistic\n",
    "\n",
    "    # Almacenamos los resultados\n",
    "    all_corrdists.append(corr_dist)\n",
    "    all_corrpreds.append(corr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(subsamples[1:], np.abs(all_corrdists - full_corr_dist), label=\"CorrDist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a evaluar con todas las ventanas, solo la distancia de correlación.\n",
    "Esto nos permitirá tener al menos una idea de como se comporta en promedio para una imagen.\n",
    "Finalmente, si combinamos para multiples imagenes podriamos recrear la figura que hice antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsamples = np.linspace(0, 2560, 21, dtype=int)\n",
    "windows_corrdists = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window in tqdm(windows):\n",
    "    results = {name: [] for name in [\"distVect\", \"predVect\"]}\n",
    "    with torch.no_grad():\n",
    "        # Para evitar procesar imagenes vacias\n",
    "        if np.sum(window) == 0:\n",
    "            continue\n",
    "\n",
    "        # Preprocesamos la ventana\n",
    "        window_tensor = torch.from_numpy(window).to(device)\n",
    "        window_tensor = transforms(window_tensor)\n",
    "\n",
    "        model_output = model(window_tensor)\n",
    "        image_pred = torch.sigmoid(model_output[\"Classifier\"])  # predicción\n",
    "        image_vect = model_output[\"Features\"]  # obtenemos las features internas\n",
    "\n",
    "        for masks in tqdm(make_masks(n_iters, mask_shape), total=n_iters, leave=False):\n",
    "            # aplicamos la mascara\n",
    "            masked_window = window_tensor * masks\n",
    "            masked_output = model(masked_window)\n",
    "            # Obtenemos la predicción y las features internas para cada subset de mascaras\n",
    "            masked_pred = torch.sigmoid(masked_output[\"Classifier\"])\n",
    "            masked_vect = masked_output[\"Features\"]\n",
    "\n",
    "            # Calculamos la distancia entre los features originales y enmascarados\n",
    "            dist_vectors = distance_fn(image_vect, masked_vect).squeeze()\n",
    "            results[\"distVect\"].append(dist_vectors)\n",
    "\n",
    "            # Distancia entre predicciones originales y enmascaradas\n",
    "            pred_vectors = distance_fn(image_pred, masked_pred).squeeze()\n",
    "            results[\"predVect\"].append(pred_vectors)\n",
    "\n",
    "        # Concatenamos los resultados\n",
    "        results[\"distVect\"] = (\n",
    "            torch.cat(results[\"distVect\"], dim=0).detach().cpu().numpy()\n",
    "        )\n",
    "        results[\"predVect\"] = (\n",
    "            torch.cat(results[\"predVect\"], dim=0).detach().cpu().numpy()\n",
    "        )\n",
    "\n",
    "    # Correlacion que evaluaremos\n",
    "    # Correlación entre distancia de features y distancia de predicciones\n",
    "    full_corr_dist = pearsonr(results[\"distVect\"], results[\"predVect\"]).statistic\n",
    "\n",
    "    # Submuestras\n",
    "    corr_dists = []\n",
    "    for n_subsamples in subsamples[1:]:\n",
    "        # Tomamos un subconjunto de las distancias y predicciones\n",
    "        sub_distvect = results[\"distVect\"][:n_subsamples]\n",
    "        sub_predvect = results[\"predVect\"][:n_subsamples]\n",
    "        # Correlación entre distancia de features y distancia de predicciones\n",
    "        corr_dist = pearsonr(sub_distvect, sub_predvect).statistic\n",
    "        corr_dists.append(corr_dist)\n",
    "\n",
    "    windows_corrdists.append(corr_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_corrdists = np.array(windows_corrdists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logscale = True\n",
    "if logscale:\n",
    "    diffs = np.abs(windows_corrdists - windows_corrdists[:, -1][..., np.newaxis])\n",
    "else:\n",
    "    diffs = windows_corrdists - windows_corrdists[:, -1][..., np.newaxis]\n",
    "boxwidth = 80\n",
    "rng_width = 0.45 * boxwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 9))\n",
    "\n",
    "# Como aparecen nans vamos a filtrar a la mala\n",
    "nanmask = ~np.isnan(diffs)\n",
    "filtered_diffs = [d[m] for d, m in zip(diffs.T, nanmask.T)]\n",
    "\n",
    "bp = ax.boxplot(\n",
    "    filtered_diffs,\n",
    "    positions=subsamples[1:],\n",
    "    showfliers=False,\n",
    "    widths=boxwidth,\n",
    "    boxprops=dict(color=\"darkblue\", linewidth=1.5),\n",
    "    whiskerprops=dict(color=\"darkblue\", linewidth=1.5),\n",
    "    medianprops=dict(color=\"crimson\", linewidth=2),\n",
    "    capprops=dict(color=\"darkblue\", linewidth=2),\n",
    "    zorder=1,\n",
    ")\n",
    "\n",
    "for diff, subsamp in zip(diffs.T, subsamples[1:]):\n",
    "    ax.scatter(\n",
    "        np.random.uniform(subsamp - rng_width, subsamp + rng_width, size=len(diff)),\n",
    "        diff,\n",
    "        alpha=0.25,\n",
    "        marker=\"x\",\n",
    "        s=1,\n",
    "        color=\"slategray\",\n",
    "        zorder=-1,\n",
    "    )\n",
    "\n",
    "# Configuración\n",
    "# ax.set_title('Correlation difference within image at different mask samples')\n",
    "ax.set_title(\n",
    "    \"Diferencia de correlación dentro de imagen a diferentes muestras de mascaras\",\n",
    "    fontsize=22,\n",
    "    fontname=\"Swis721 BT\",\n",
    "    wrap=True,\n",
    ")\n",
    "\n",
    "# ax.set_xlabel('Number of masks')\n",
    "ax.set_xlabel(\"Número de mascaras\", fontsize=16, fontname=\"Swis721 BT\")\n",
    "ax.set_xticklabels(\n",
    "    subsamples[1:], rotation=45, ha=\"center\", fontsize=12\n",
    ")  # rotar la etiqueta de x\n",
    "# ax.set_ylabel('Correlation difference with full set')\n",
    "ax.set_ylabel(\n",
    "    \"Diferencia de correlación con el conjunto completo\",\n",
    "    fontsize=14,\n",
    "    fontname=\"Swis721 BT\",\n",
    "    wrap=True,\n",
    ")\n",
    "ax.set_ylim(-0.2, 0.2)\n",
    "\n",
    "# Lineas de referencia\n",
    "ax.axhline(\n",
    "    0.05,\n",
    "    color=\"coral\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2.5,\n",
    "    alpha=0.75,\n",
    "    zorder=0,\n",
    "    label=r\"$\\pm 0.05$\",\n",
    ")\n",
    "# ax.axhline(-0.05, color='coral', linestyle='--', alpha=0.75, zorder=0)\n",
    "\n",
    "ax.axhline(\n",
    "    0.025,\n",
    "    color=\"firebrick\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2.5,\n",
    "    alpha=0.75,\n",
    "    zorder=0,\n",
    "    label=r\"$\\pm 0.025$\",\n",
    ")\n",
    "# ax.axhline(-0.025, color='firebrick', linestyle='--', alpha=0.75, zorder=0)\n",
    "\n",
    "# IDEA: como plotear un boxplot con eje y logaritmico\n",
    "if logscale:\n",
    "    # ax.set_ylabel('Correlation difference with full set (Log Scale)')\n",
    "    ax.set_ylabel(\n",
    "        \"Diferencia de correlación con el conjunto completo (Escala Logarítmica)\",\n",
    "        fontsize=16,\n",
    "        fontname=\"Swis721 BT\",\n",
    "        wrap=True,\n",
    "    )\n",
    "    ax.tick_params(axis=\"y\", labelsize=12, labelfontfamily=\"Swis721 BT\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylim(0.0005, 1.001)\n",
    "\n",
    "ax.legend()\n",
    "# fig.savefig('06-LogCorrDiffs.jpg', dpi=300, bbox_inches='tight')\n",
    "fig.savefig(\"plots_tesis/LogCorrDiffs.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff = np.abs(windows_corrdists - windows_corrdists[:, -1][..., np.newaxis]).mean(\n",
    "    axis=0\n",
    ")\n",
    "plt.plot(subsamples[1:], mean_diff, label=\"MeanDiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    subsamples[1:],\n",
    "    np.array(windows_corrdists).mean(axis=0),\n",
    "    label=\"CorrDist (Ventanas)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamai2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
