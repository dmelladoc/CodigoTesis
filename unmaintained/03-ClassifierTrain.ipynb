{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the pathological finding classifier\n",
    "\n",
    "After we identified our model `EfficientNetV2`, we train our classifier with all samples.\n",
    "\n",
    "The idea on this, is to get crops at different ranges of scales and aspect ratios to train our classifier.\n",
    "Then train this classifier using our best parameters found on [the earlier notebook](02-GridSearch.ipynb).\n",
    "\n",
    "Finally, we save the trained model and do some inference using our explainable algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "\n",
    "from torchmetrics.classification import (\n",
    "    MultilabelAccuracy,\n",
    "    MultilabelPrecision,\n",
    "    MultilabelRecall,\n",
    "    MultilabelF1Score,\n",
    "    MultilabelAUROC,\n",
    ")\n",
    "from torchinfo import summary\n",
    "\n",
    "from FindClf import Dataset, Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "imagepath = \"\"  # Image directory with vindr Dataset images processed with our method\n",
    "csvpath = (\n",
    "    \"finding_annotations_V2.csv\"  # Grouped annotations for asymmetries and retractions\n",
    ")\n",
    "label_names = [\n",
    "    \"No Finding\",\n",
    "    \"Mass\",\n",
    "    \"Suspicious Calcification\",\n",
    "    \"Asymmetries\",\n",
    "    \"Architectural Distortion\",\n",
    "    \"Suspicious Lymph Node\",\n",
    "    \"Skin Thickening\",\n",
    "    \"Retractions\",\n",
    "]\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "scales = (0.05, 5.0)\n",
    "ratios = (0.33, 1.66)\n",
    "window_size = (256, 256)\n",
    "\n",
    "# Hyperparameters found by Ray Tune\n",
    "lr = 0.0001\n",
    "weight_decay = 1e-5\n",
    "focal_alpha = 0.8  # 0.95 was the best value but is kind of too high\n",
    "focal_gamma = 2.0  # 2.0 was as expected though\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "njobs = 16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## instanciate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set transforms\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(\n",
    "            degrees=30, interpolation=transforms.InterpolationMode.BILINEAR\n",
    "        ),\n",
    "        transforms.RandomApply(\n",
    "            [\n",
    "                transforms.ColorJitter(\n",
    "                    brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1\n",
    "                ),\n",
    "                transforms.RandomChannelPermutation(),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        transforms.Resize(\n",
    "            window_size,\n",
    "            interpolation=transforms.InterpolationMode.BILINEAR,\n",
    "            antialias=True,\n",
    "        ),\n",
    "        transforms.ToDtype(torch.float32, scale=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(\n",
    "            window_size,\n",
    "            interpolation=transforms.InterpolationMode.BILINEAR,\n",
    "            antialias=True,\n",
    "        ),\n",
    "        transforms.ToDtype(torch.float32, scale=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(csvpath)\n",
    "df_train = df.groupby(\"split\").get_group(\"training\")\n",
    "df_test = df.groupby(\"split\").get_group(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset objects\n",
    "train_dataset = Dataset.VindrDataset(\n",
    "    df_train, imagepath, train_transforms, stage=\"train\"\n",
    ")\n",
    "test_dataset = Dataset.VindrDataset(df_test, imagepath, test_transforms, stage=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted sampler functions\n",
    "def get_class_weights(dataset):\n",
    "    events_per_class = np.zeros_like(label_names, dtype=np.int64)\n",
    "    for val in dataset.df.finding_categories:\n",
    "        for label in literal_eval(val):\n",
    "            idx = label_names.index(label)\n",
    "            events_per_class[idx] += 1\n",
    "    n_samples = len(dataset)\n",
    "    class_weights = n_samples / events_per_class\n",
    "    return class_weights\n",
    "\n",
    "\n",
    "def get_sample_weights(dataset):\n",
    "    sample_weights = []\n",
    "    class_weights = get_class_weights(dataset)\n",
    "    for val in dataset.df.finding_categories:\n",
    "        label = literal_eval(val)\n",
    "        sample_weight = [class_weights[label_names.index(l)] for l in label]\n",
    "        sample_weights.append(sum(sample_weight))\n",
    "    return np.array(sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the sampler\n",
    "class_weights = get_class_weights(train_dataset)\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "train_weights = get_sample_weights(train_dataset)\n",
    "sampler = WeightedRandomSampler(train_weights, len(train_weights), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, num_workers=njobs, sampler=sampler\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, num_workers=njobs, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Models.create_efficientNetV2(len(label_names))\n",
    "model.to(device)\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(1, 3, 256, 256),\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "    depth=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and schedulers\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=epochs, eta_min=1e-7, last_epoch=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"Accuracy\": MultilabelAccuracy(\n",
    "        num_labels=len(label_names), average=\"macro\", ignore_index=0\n",
    "    ),\n",
    "    \"F1\": MultilabelF1Score(\n",
    "        num_labels=len(label_names), average=\"macro\", ignore_index=0\n",
    "    ),\n",
    "    \"AUC\": MultilabelAUROC(\n",
    "        num_labels=len(label_names), average=\"weighted\", ignore_index=0, thresholds=10\n",
    "    ),\n",
    "}\n",
    "\n",
    "[metric.to(device) for metric in metrics.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_carpeta(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "start = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "ckpt_path = f\"checkpoints/{start}\"\n",
    "crear_carpeta(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(total=epochs, desc=\"Training\") as trainbar:\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()  # set the model to training mode\n",
    "\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        train_loss = 0.0\n",
    "        [metric.reset() for metric in metrics.values()]  # reset the metrics\n",
    "        with tqdm(\n",
    "            total=len(train_loader), desc=f\"Training (lr={current_lr:.2e})\", leave=False\n",
    "        ) as pbar:\n",
    "            for i, (images, labels) in enumerate(train_loader, 1):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)  # forward pass\n",
    "                loss = sigmoid_focal_loss(\n",
    "                    outputs[\"Classifier\"],\n",
    "                    labels,\n",
    "                    alpha=focal_alpha,\n",
    "                    gamma=focal_gamma,\n",
    "                    reduction=\"sum\",\n",
    "                )\n",
    "                loss.backward()  # backward pass\n",
    "                optimizer.step()\n",
    "\n",
    "                # metrics\n",
    "                train_loss += loss.item()\n",
    "                metric_text = f\"Loss: {train_loss / i:.4f}\"\n",
    "                for name, metric in metrics.items():\n",
    "                    metric.update(outputs[\"Classifier\"], labels.int())\n",
    "                    metric_text += f\" {name}: {metric.compute():.4f}\"\n",
    "                pbar.set_postfix_str(metric_text)\n",
    "                pbar.update()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()  # set the model to evaluation mode\n",
    "        [metric.reset() for metric in metrics.values()]  # reset the metrics\n",
    "        val_loss = 0.0\n",
    "        with tqdm(total=len(test_loader), desc=\"Validation\", leave=False) as pbar:\n",
    "            for i, (images, labels) in enumerate(test_loader, 1):\n",
    "                with torch.no_grad():\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                    outputs = model(images)  # forward pass\n",
    "                    loss = sigmoid_focal_loss(\n",
    "                        outputs[\"Classifier\"],\n",
    "                        labels,\n",
    "                        alpha=focal_alpha,\n",
    "                        gamma=focal_gamma,\n",
    "                        reduction=\"sum\",\n",
    "                    )\n",
    "\n",
    "                    # metrics\n",
    "                    val_loss += loss.item()\n",
    "                    metric_text = f\"Loss: {val_loss / i:.4f}\"\n",
    "                    for name, metric in metrics.items():\n",
    "                        metric.update(outputs[\"Classifier\"], labels.int())\n",
    "                        metric_text += f\" {name}: {metric.compute():.4f}\"\n",
    "                    pbar.set_postfix_str(metric_text)\n",
    "                    pbar.update()\n",
    "\n",
    "        # Post-epoch operations\n",
    "        # update the progress bar\n",
    "        trainbar.set_postfix_str(\n",
    "            f\" F1: {metrics['F1'].compute():.4f} AUROC: {metrics['AUC'].compute():.4f}\"\n",
    "        )\n",
    "        trainbar.update()\n",
    "\n",
    "        scheduler.step()  # update the learning rate\n",
    "        if epoch % 10 == 0:\n",
    "            current_ckpt = os.path.join(\n",
    "                ckpt_path, f\"EfficientNetV2_epoch{epoch:03d}.pth\"\n",
    "            )\n",
    "            save_dict = {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            }\n",
    "            torch.save(save_dict, current_ckpt)\n",
    "\n",
    "# Save the final model\n",
    "current_ckpt = os.path.join(ckpt_path, f\"EfficientNetV2_final.pth\")\n",
    "save_dict = {\n",
    "    \"epoch\": epoch,\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "}\n",
    "torch.save(save_dict, current_ckpt)\n",
    "print(f\"Model saved at {current_ckpt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamai2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
